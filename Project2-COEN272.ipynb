{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project2 for COEN272 \n",
    "# Dengwei Wang 00001599188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading training data and test data into array\n",
    "import numpy\n",
    "data = numpy.loadtxt(\"train.txt\", dtype = int)\n",
    "test5 = numpy.loadtxt(\"test5.txt\", dtype = int)\n",
    "test10 = numpy.loadtxt(\"test10.txt\", dtype = int)\n",
    "test20 = numpy.loadtxt(\"test20.txt\", dtype = int)\n",
    "data_arr = [[0 for _ in range(1000)] for _ in range(200)]\n",
    "test5_arr = [[0 for _ in range(1000)] for _ in range(100)]\n",
    "test10_arr = [[0 for _ in range(1000)] for _ in range(100)]\n",
    "test20_arr = [[0 for _ in range(1000)] for _ in range(100)]\n",
    "for u,m,r in data:\n",
    "    data_arr[u-1][m-1] = r\n",
    "for u,m,r in test5:\n",
    "    test5_arr[u-201][m-1] = r \n",
    "for u,m,r in test10:\n",
    "    test10_arr[u-301][m-1] = r \n",
    "for u,m,r in test20:\n",
    "    test20_arr[u-401][m-1] = r "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine-Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating cosine similarity\n",
    "def cosine_sim(vector1, vector2):\n",
    "    if len(vector1) != len(vector2): \n",
    "        print(\"dimension error!!\")\n",
    "        return 0\n",
    "    v1, v2 = [], []\n",
    "    num, norm1, norm2 = 0, 0.0, 0.0\n",
    "    for i,j in zip(vector1,vector2):\n",
    "        if i != 0 and j != 0:\n",
    "            v1.append(i)\n",
    "            v2.append(j)\n",
    "            num += i*j\n",
    "            norm1 += i*i\n",
    "            norm2 += j*j\n",
    "    if num == 0: return 0\n",
    "    if len(v1) == 1:  #only one common rating\n",
    "        return 1 - abs(v1[0] - v2[0])/4  #rate the similarity by 5 ranks based on the difference: 0,0.25,0.5,0.75,1\n",
    "    return num / ((norm1**0.5)*(norm2**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating cosine similarity ranking list between each user in test data with each user in training data\n",
    "def get_cos_similarity_mat(training_data, test_data):\n",
    "    mat = [[0 for _ in range(200)] for _ in range(100)]\n",
    "    for i in range(100):\n",
    "        for j in range(200):\n",
    "            mat[i][j] = cosine_sim(test_data[i], training_data[j])\n",
    "    return mat\n",
    "\n",
    "# get the ranking of users based on cosine similarity in descending order\n",
    "def rank_similarity(mat):\n",
    "    res, abs_cos_sim = [],[]\n",
    "    for u in mat:\n",
    "        for cos in u:\n",
    "            abs_cos_sim.append(abs(cos))\n",
    "        res.append(list(numpy.argsort(abs_cos_sim))[::-1])\n",
    "        abs_cos_sim = []\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim5 = get_cos_similarity_mat(data_arr, test5_arr)\n",
    "cos_sim10 = get_cos_similarity_mat(data_arr, test10_arr)\n",
    "cos_sim20 = get_cos_similarity_mat(data_arr, test20_arr)\n",
    "rank5 = rank_similarity(cos_sim5)\n",
    "rank10 = rank_similarity(cos_sim10)\n",
    "rank20 = rank_similarity(cos_sim20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the ranking based on baisc user-based collaborative filtering algorithms -- cosine similarity method\n",
    "def cos_sim_rating_prediction(test_data, test_ranking, test_cossim_mat, training_data, id_shift, k):\n",
    "    res_arr = []\n",
    "    for i in test_data:\n",
    "        if list(i)[2] == 0:\n",
    "            res_arr.append(list(i))\n",
    "    for i,j in enumerate(res_arr):\n",
    "        user_id = j[0] - id_shift\n",
    "        movie_id = j[1] - 1\n",
    "        cnt = 0\n",
    "        num, deno = 0.0, 0.0\n",
    "        for m in test_ranking[user_id]:\n",
    "            cos_sim = test_cossim_mat[user_id][m]\n",
    "            rate_in_training = training_data[m][movie_id]\n",
    "            if rate_in_training and cos_sim > 0.3:\n",
    "                num += cos_sim*rate_in_training\n",
    "                deno += cos_sim\n",
    "                cnt += 1\n",
    "                if cnt >= k: break\n",
    "        if num == 0 and deno == 0: # rate 3 for default when there are no similar user\n",
    "            res_arr[i][2] = 3\n",
    "            continue\n",
    "        res_arr[i][2] = int(round(num/deno, 0)) #num/deno\n",
    "    return res_arr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_res5 = cos_sim_rating_prediction(test5, rank5, cos_sim5, data_arr, 201, 30)\n",
    "rate_res10 = cos_sim_rating_prediction(test10, rank10, cos_sim10, data_arr, 301, 30)\n",
    "rate_res20 = cos_sim_rating_prediction(test20, rank20, cos_sim20, data_arr, 401, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(res, res_file):\n",
    "    with open(res_file, 'w') as f:\n",
    "        for l in res:\n",
    "            f.write(str(l)[1:-1].replace(',',''))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(rate_res5, 'cos_sim_rating_res5.txt')\n",
    "write_file(rate_res10, 'cos_sim_rating_res10.txt')\n",
    "write_file(rate_res20, 'cos_sim_rating_res20.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating Prediction -- Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pearson_weight(vec1, vec2): #vectors of same size stand for same set of movies\n",
    "    v1, v2 = [], []\n",
    "    for i in range(len(vec1)):\n",
    "        if vec1[i] != 0 and vec2[i] != 0:\n",
    "            v1.append(vec1[i])\n",
    "            v2.append(vec2[i])\n",
    "    if len(v1) == 0: \n",
    "        return 0\n",
    "    if len(v1) == 1:\n",
    "        # return 1 - abs(v1[0]-v2[0])/2  #weight  -1, -0.5, 0, 0.5, 1 when only one similar item\n",
    "        return 1 - abs(v1[0]-v2[0])/4  #weight  0, 0.25, 0.5, 0.75, 1 when only one similar item\n",
    "    r_a, r_u = sum(v1)/len(v1), sum(v2)/len(v2)\n",
    "    num, deno = 0.0, 0.0\n",
    "    for i in range(len(v1)):\n",
    "        v1[i] -= r_a \n",
    "        v2[i] -= r_u\n",
    "    num = sum([m*n for m,n in zip(v1,v2)])\n",
    "    deno = (sum([m*m for m in v1])**0.5) * (sum([n*n for n in v2])**0.5)\n",
    "    if deno == 0: \n",
    "        # return 1 - abs(r_a - r_u)/2\n",
    "        return 1 - abs(r_a - r_u)/4\n",
    "    weight = num/deno\n",
    "    return weight\n",
    "\n",
    "def get_r_u_value(vec1, vec2):\n",
    "    v1, v2 = [], []\n",
    "    for i in range(len(vec1)):\n",
    "        if vec1[i] != 0 and vec2[i] != 0:\n",
    "            v1.append(vec1[i])\n",
    "            v2.append(vec2[i])\n",
    "    if len(v1) == 0: \n",
    "        return 0\n",
    "    return sum(v2)/len(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pearson_weight_mat(training_data, test_data):\n",
    "    mat = [[0 for _ in range(200)] for _ in range(100)]\n",
    "    for i in range(100):\n",
    "        for j in range(200):\n",
    "            mat[i][j] = calculate_pearson_weight(test_data[i], training_data[j])\n",
    "    return mat\n",
    "\n",
    "def get_pearson_r_a_mat(test_data):\n",
    "    res = []\n",
    "    for i in test_data:\n",
    "        cnt, s = 0, 0.0\n",
    "        for j in i:\n",
    "            if j > 0:\n",
    "                cnt += 1\n",
    "                s += j\n",
    "        if cnt != 0:\n",
    "            res.append(s/cnt)\n",
    "        else: \n",
    "            res.append(0)\n",
    "    return res\n",
    "\n",
    "def get_pearson_r_u_mat(training_data, test_data):\n",
    "    r_u = [[0 for _ in range(200)] for _ in range(100)]\n",
    "    for i in range(100):\n",
    "        for j in range(200):\n",
    "            r_u[i][j] = get_r_u_value(test_data[i], training_data[j])\n",
    "    return r_u\n",
    "\n",
    "def rank_pearson_weight(mat):\n",
    "    res, abs_pear_weight = [],[]\n",
    "    for u in mat:\n",
    "        for pear in u:\n",
    "            abs_pear_weight.append(pear) # abs(pear)\n",
    "        res.append(list(numpy.argsort(abs_pear_weight))[::-1])\n",
    "        abs_pear_weight = []\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_r_a_test5 = get_pearson_r_a_mat(test5_arr)\n",
    "pearson_r_a_test10 = get_pearson_r_a_mat(test10_arr)\n",
    "pearson_r_a_test20 = get_pearson_r_a_mat(test20_arr)\n",
    "pearson_weight_test5 = get_pearson_weight_mat(data_arr, test5_arr)\n",
    "pearson_ranking_test5 = rank_pearson_weight(pearson_weight_test5)\n",
    "pearson_weight_test10 = get_pearson_weight_mat(data_arr, test10_arr)\n",
    "pearson_ranking_test10 = rank_pearson_weight(pearson_weight_test10)\n",
    "pearson_weight_test20 = get_pearson_weight_mat(data_arr, test20_arr)\n",
    "pearson_ranking_test20 = rank_pearson_weight(pearson_weight_test20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_r_u_test5 = get_pearson_r_u_mat(data_arr, test5_arr)\n",
    "pearson_r_u_test10 = get_pearson_r_u_mat(data_arr, test10_arr)\n",
    "pearson_r_u_test20 = get_pearson_r_u_mat(data_arr, test20_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_rating_prediction(test_data, test_ranking, test_weight_mat, r_a_mat, r_u_mat, training_data, id_shift, k):\n",
    "    res_arr = []\n",
    "    for i in test_data:\n",
    "        if list(i)[2] == 0:\n",
    "            res_arr.append(list(i))\n",
    "    for i,j in enumerate(res_arr):\n",
    "        user_id = j[0] - id_shift\n",
    "        movie_id = j[1] - 1\n",
    "        r_a = r_a_mat[user_id]\n",
    "        cnt = 0\n",
    "        num, deno = 0.0, 0.0\n",
    "        for m in test_ranking[user_id]:\n",
    "            weight = test_weight_mat[user_id][m]\n",
    "            rate_in_training = training_data[m][movie_id]\n",
    "            r_u = r_u_mat[user_id][m]\n",
    "            if rate_in_training and weight > 0.3:\n",
    "                num += weight*(rate_in_training - r_u)\n",
    "                deno += abs(weight)\n",
    "                cnt += 1\n",
    "                if cnt >= k: break\n",
    "        if num == 0 and deno == 0: # rate its mean rating for default when there are no similar user\n",
    "            res_arr[i][2] = int(round(r_a, 0))\n",
    "            continue\n",
    "        ans = int(round(r_a + num/deno, 0)) # r_a + num/deno\n",
    "        if ans > 5: ans = 5\n",
    "        elif ans < 1: ans = 1\n",
    "        res_arr[i][2] = ans\n",
    "    return res_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_out5 = pearson_rating_prediction(test5, pearson_ranking_test5, pearson_weight_test5, pearson_r_a_test5, pearson_r_u_test5, data_arr, 201, 30)\n",
    "pearson_out10 = pearson_rating_prediction(test10, pearson_ranking_test10, pearson_weight_test10, pearson_r_a_test10, pearson_r_u_test10, data_arr, 301, 30)\n",
    "pearson_out20 = pearson_rating_prediction(test20, pearson_ranking_test20, pearson_weight_test20, pearson_r_a_test20, pearson_r_u_test20, data_arr, 401, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(pearson_out5, 'pearson_rating_res5_05271530.txt')\n",
    "write_file(pearson_out10, 'pearson_rating_res10_05271530.txt')\n",
    "write_file(pearson_out20, 'pearson_rating_res20_05271530.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson Correlation with IUF (Inverse user frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_iuf_arr(training_data):\n",
    "    movie_rating_cnt = [0 for _ in range(1000)]\n",
    "    iuf_arr = []\n",
    "    for u_id,movies in enumerate(training_data):\n",
    "        cnt = 0\n",
    "        for m_id,rate in enumerate(movies):\n",
    "            if rate > 0:\n",
    "                movie_rating_cnt[m_id] += 1\n",
    "    for n in movie_rating_cnt:\n",
    "        if n != 0:\n",
    "            iuf_arr.append(math.log10(200/n)) \n",
    "        else:\n",
    "            iuf_arr.append(1)\n",
    "    return iuf_arr\n",
    "\n",
    "def get_iuf_train_arr(training_data, iuf_arr):\n",
    "    iuf_data_arr = [[0 for _ in range(1000)] for _ in range(200)]\n",
    "    for i in range(len(training_data)):\n",
    "        for j in range(1000):\n",
    "            iuf_data_arr[i][j] = round(training_data[i][j]*iuf_arr[j],3)\n",
    "    return iuf_data_arr\n",
    "\n",
    "def get_iuf_test_arr(test_data, iuf_arr):\n",
    "    iuf_test_arr = [[0 for _ in range(1000)] for _ in range(100)]\n",
    "    for i in range(len(test_data)):\n",
    "        for j in range(1000):\n",
    "            iuf_test_arr[i][j] = round(test_data[i][j]*iuf_arr[j],3)\n",
    "    return iuf_test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iuf_arr = get_iuf_arr(data_arr)\n",
    "iuf_data_arr = get_iuf_train_arr(data_arr, iuf_arr)\n",
    "iuf_test5_arr = get_iuf_test_arr(test5_arr, iuf_arr)\n",
    "iuf_test10_arr = get_iuf_test_arr(test10_arr, iuf_arr)\n",
    "iuf_test20_arr = get_iuf_test_arr(test20_arr, iuf_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculate the rating and weight matrix using the modified data\n",
    "pearson_iuf_r_a_test5 = get_pearson_r_a_mat(iuf_test5_arr)\n",
    "pearson_iuf_r_a_test10 = get_pearson_r_a_mat(iuf_test10_arr)\n",
    "pearson_iuf_r_a_test20 = get_pearson_r_a_mat(iuf_test20_arr)\n",
    "pearson_weight_iuf_test5 = get_pearson_weight_mat(iuf_data_arr, test5_arr)\n",
    "pearson_ranking_iuf_test5 = rank_pearson_weight(pearson_weight_iuf_test5)\n",
    "pearson_weight_iuf_test10 = get_pearson_weight_mat(iuf_data_arr, test10_arr)\n",
    "pearson_ranking_iuf_test10 = rank_pearson_weight(pearson_weight_iuf_test10)\n",
    "pearson_weight_iuf_test20 = get_pearson_weight_mat(iuf_data_arr, test20_arr)\n",
    "pearson_ranking_iuf_test20 = rank_pearson_weight(pearson_weight_iuf_test20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_iuf_r_u_test5 = get_pearson_r_u_mat(iuf_data_arr, iuf_test5_arr)\n",
    "pearson_iuf_r_u_test10 = get_pearson_r_u_mat(iuf_data_arr, iuf_test10_arr)\n",
    "pearson_iuf_r_u_test20 = get_pearson_r_u_mat(iuf_data_arr, iuf_test20_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_iuf_out5 = pearson_rating_prediction(test5, pearson_ranking_iuf_test5, pearson_weight_iuf_test5, pearson_r_a_test5, pearson_r_u_test5, data_arr, 201, 30)\n",
    "pearson_iuf_out10 = pearson_rating_prediction(test10, pearson_ranking_iuf_test10, pearson_weight_iuf_test10, pearson_r_a_test10, pearson_r_u_test10, data_arr, 301, 30)\n",
    "pearson_iuf_out20 = pearson_rating_prediction(test20, pearson_ranking_iuf_test20, pearson_weight_iuf_test20, pearson_r_a_test20, pearson_r_u_test20, data_arr, 401, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(pearson_iuf_out5, 'pearson_iuf_rating_res5_05282124.txt')\n",
    "write_file(pearson_iuf_out10, 'pearson_iuf_rating_res10_05282124.txt')\n",
    "write_file(pearson_iuf_out20, 'pearson_iuf_rating_res20_05282124.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson Correlation With Case Amplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the case amplified weight matrix\n",
    "def get_amp_pearson_weight_mat(weight_mat):\n",
    "    for i in range(len(weight_mat)):\n",
    "        for j in range(len(weight_mat[0])):\n",
    "            weight_mat[i][j] *= math.pow(abs(weight_mat[i][j]),1.5)\n",
    "    return weight_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_amp_weight_test5 = get_amp_pearson_weight_mat(pearson_weight_test5)\n",
    "pearson_amp_weight_test10 = get_amp_pearson_weight_mat(pearson_weight_test10)\n",
    "pearson_amp_weight_test20 = get_amp_pearson_weight_mat(pearson_weight_test20)\n",
    "pearson_amp_ranking_test5 = rank_pearson_weight(pearson_amp_weight_test5)\n",
    "pearson_amp_ranking_test10 = rank_pearson_weight(pearson_amp_weight_test10)\n",
    "pearson_amp_ranking_test20 = rank_pearson_weight(pearson_amp_weight_test20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_amp_out5 = pearson_rating_prediction(test5, pearson_amp_ranking_test5, pearson_amp_weight_test5, pearson_r_a_test5, pearson_r_u_test5, data_arr, 201, 30)\n",
    "pearson_amp_out10 = pearson_rating_prediction(test10, pearson_amp_ranking_test10, pearson_amp_weight_test10, pearson_r_a_test10, pearson_r_u_test10, data_arr, 301, 30)\n",
    "pearson_amp_out20 = pearson_rating_prediction(test20, pearson_amp_ranking_test20, pearson_amp_weight_test20, pearson_r_a_test20, pearson_r_u_test20, data_arr, 401, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(pearson_amp_out5, 'pearson_amp_rating_res5_05271750.txt')\n",
    "write_file(pearson_amp_out10, 'pearson_amp_rating_res10_05271750.txt')\n",
    "write_file(pearson_amp_out20, 'pearson_amp_rating_res20_05271750.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_rated_movies_mat(test_data, movie_cnt, shift_id):\n",
    "    res_arr = [[] for _ in range(100)]\n",
    "    for i in test_data:\n",
    "        user_id, movie_id, rating = list(i)[0] - shift_id, list(i)[1] - 1, list(i)[2]\n",
    "        if rating != 0:\n",
    "            res_arr[user_id].append((movie_id, rating))\n",
    "        else:\n",
    "            continue\n",
    "    return res_arr\n",
    "\n",
    "def get_adj_cos_sim(vec1, vec2, r_u):\n",
    "    v1, v2 = [], []\n",
    "    for i in range(len(vec1)):\n",
    "        if vec1[i] != 0 and vec2[i] != 0:\n",
    "            v1.append(vec1[i])\n",
    "            v2.append(vec2[i])\n",
    "    if len(v1) == 0: \n",
    "        return 0\n",
    "    if len(v1) == 1:\n",
    "        return 1 - abs(v1[0]-v2[0])/4  #weight 0, 0.25, 0.5, 0.75, 1 when only one similar item\n",
    "    r_a, r_u = sum(v1)/len(v1), sum(v2)/len(v2)\n",
    "    num, deno = 0.0, 0.0\n",
    "    for i in range(len(v1)):\n",
    "        v1[i] -= r_u \n",
    "        v2[i] -= r_u\n",
    "    num = sum([m*n for m,n in zip(v1,v2)])\n",
    "    deno = (sum([m*m for m in v1])**0.5) * (sum([n*n for n in v2])**0.5)\n",
    "    if deno == 0: \n",
    "        return 0\n",
    "    return num/deno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test5_rated_movie_mat = get_test_rated_movies_mat(test5, 5, 201)\n",
    "test10_rated_movie_mat = get_test_rated_movies_mat(test10, 10, 301)\n",
    "test20_rated_movie_mat = get_test_rated_movies_mat(test20, 20, 401)\n",
    "test5_mean = pearson_r_a_test5\n",
    "test10_mean = pearson_r_a_test10\n",
    "test20_mean = pearson_r_a_test20\n",
    "data_arr_t = numpy.array(data_arr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_rating_prediction(test_data, train_data_t, test_movie_mat, test_mean, shift_id, k):\n",
    "    res_arr = []\n",
    "    for i in test_data:\n",
    "        if list(i)[2] == 0:\n",
    "            res_arr.append(list(i))\n",
    "    for i,j in enumerate(res_arr):\n",
    "        user_id = j[0] - shift_id\n",
    "        movie_id = j[1] - 1\n",
    "        cnt = 0\n",
    "        num, deno = 0.0, 0.0\n",
    "        sim_list = []\n",
    "        for m in test_movie_mat[user_id]:\n",
    "            sim_list.append(get_adj_cos_sim(train_data_t[m[0]], train_data_t[movie_id], test_mean[user_id]))\n",
    "        rank_index = list(numpy.argsort(sim_list)[-k:])[::-1]\n",
    "        for idx in rank_index:\n",
    "            rating = test_movie_mat[user_id][idx][1]\n",
    "            if sim_list[idx] > 0.3:\n",
    "                num += rating*sim_list[idx]\n",
    "                deno += sim_list[idx]\n",
    "        if num == 0 and deno == 0: # rate 3 for default when there are no similar user\n",
    "            res_arr[i][2] = 3\n",
    "            continue\n",
    "        ans = int(round(num/deno, 0))\n",
    "        if ans > 5: ans = 5\n",
    "        elif ans < 1: ans = 1\n",
    "        res_arr[i][2] = ans\n",
    "    return res_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_out5 = item_based_rating_prediction(test5, data_arr_t, test5_rated_movie_mat, test5_mean, 201, 4)\n",
    "item_out10 = item_based_rating_prediction(test10, data_arr_t, test10_rated_movie_mat, test10_mean, 301, 8)\n",
    "item_out20 = item_based_rating_prediction(test20, data_arr_t, test20_rated_movie_mat, test20_mean, 401, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(item_out5, 'item_base_res5_05281927.txt')\n",
    "write_file(item_out10, 'item_base_res10_05281927.txt')\n",
    "write_file(item_out20, 'item_base_res20_05281927.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Own algorithm get rating from weighted Cosine Similarity and Pearson Correlation\n",
    "def own_alg(out1, out2):\n",
    "    res_arr = []\n",
    "    for i,j in zip(out1, out2):\n",
    "        #mean = int(round((i[2]+j[2])/2, 0))\n",
    "        mean = int(round(i[2]*0.6+j[2]*0.4, 0))\n",
    "        #mean = int(round(i[2]*0.7+j[2]*0.3, 0))\n",
    "        if mean > 5: mean = 5\n",
    "        if mean < 1: mean = 1\n",
    "        res_arr.append([i[0], i[1], mean])\n",
    "    return res_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_out5 = own_alg(rate_res5, pearson_out5)\n",
    "own_out10 = own_alg(rate_res10, pearson_out10)\n",
    "own_out20 = own_alg(rate_res20, pearson_out20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(own_out5, 'own_rating_res5_05290014.txt')\n",
    "write_file(own_out10, 'own_rating_res10_05290014.txt')\n",
    "write_file(own_out20, 'own_rating_res20_05290014.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
